#!/usr/bin/env python3
import requests
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup

print("=" * 70)
print("CNN æ–°èçˆ¬å–æ›¿ä»£æ–¹æ¡ˆæ¸¬è©¦")
print("=" * 70)

# æ–¹æ¡ˆ 1: ä½¿ç”¨ç¬¬ä¸‰æ–¹ RSS èšåˆæœå‹™
print("\nã€æ–¹æ¡ˆ 1ã€‘ç¬¬ä¸‰æ–¹ RSS èšåˆæœå‹™")
print("-" * 70)

alternative_rss_feeds = [
    {
        "name": "RSS2JSON (CNN Business)",
        "url": "https://rss2json.com/v1/api.json?rss_url=https://edition.cnn.com/business/rss",
        "parser": "json",
    },
    {
        "name": "Feedrabbit (CNN)",
        "url": "https://feedrabbit.com/rss/cnn-business.rss",
        "parser": "xml",
    },
    {
        "name": "NewsAPI.org (éœ€è¦ API Key)",
        "note": "å…è²»ç‰ˆæ¯å¤© 100 æ¬¡è«‹æ±‚ï¼Œæœ‰ CNN Business åˆ†é¡",
        "url": "https://newsapi.org/v2/everything?domains=cnn.com&apiKey=YOUR_KEY",
        "requires_key": True,
    },
]

# æ¸¬è©¦å¯ç”¨çš„ç¬¬ä¸‰æ–¹ RSS
for feed in alternative_rss_feeds[:2]:
    if feed.get("requires_key"):
        print(f"\n{feed['name']}:")
        print(f"  ğŸ“ {feed['note']}")
        print(f"  ğŸ”‘ éœ€è¦ API Key")
        continue

    print(f"\næ¸¬è©¦: {feed['name']}")
    print(f"  URL: {feed['url']}")
    try:
        response = requests.get(feed["url"], timeout=10)
        print(f"  ç‹€æ…‹: {response.status_code}")

        if response.status_code == 200:
            if feed["parser"] == "json":
                data = response.json()
                if "status" in data and data["status"] == "ok":
                    items = data.get("items", [])
                    print(f"  âœ… æˆåŠŸ! æ‰¾åˆ° {len(items)} å‰‡æ–°è")
                    if items:
                        print(f"  ç¯„ä¾‹: {items[0].get('title', '')[:60]}...")
                else:
                    print(f"  âš ï¸ API è¿”å›éŒ¯èª¤: {data.get('message', 'Unknown')}")
            else:
                root = ET.fromstring(response.text)
                items = root.findall(".//item")
                print(f"  âœ… æˆåŠŸ! æ‰¾åˆ° {len(items)} å‰‡æ–°è")
        else:
            print(f"  âŒ è«‹æ±‚å¤±æ•—")
    except Exception as e:
        print(f"  âŒ éŒ¯èª¤: {e}")

# æ–¹æ¡ˆ 2: ä½¿ç”¨æ–°è API
print("\n\nã€æ–¹æ¡ˆ 2ã€‘æ–°è API æœå‹™")
print("-" * 70)

news_apis = [
    {
        "name": "NewsAPI.org",
        "description": "æ”¯æ´ CNNï¼Œåˆ†é¡å®Œå‚™ï¼Œå…è²» 100 æ¬¡/å¤©",
        "pricing": "å…è²»: $0/æœˆ | é–‹ç™¼è€…: $449/æœˆ",
        "domains": "cnn.com",
        "url": "https://newsapi.org/",
    },
    {
        "name": "GNews.io",
        "description": "åŒ…å« CNN ä¾†æºï¼Œå¯¦æ™‚æ–°è",
        "pricing": "å…è²»: 100 æ¬¡/å¤© | ä»˜è²»: $9.99/æœˆ",
        "domains": "cnn.com",
        "url": "https://gnews.io/",
    },
    {
        "name": "Currents API",
        "description": "å¤šèªè¨€ï¼ŒåŒ…å«è‹±æ–‡æ–°è",
        "pricing": "å…è²»: 100 æ¬¡/æœˆ | ä»˜è²»: $8/æœˆ",
        "url": "https://currentsapi.services/",
    },
]

for api in news_apis:
    print(f"\n{api['name']}:")
    print(f"  èªªæ˜: {api['description']}")
    print(f"  å®šåƒ¹: {api['pricing']}")
    if "domains" in api:
        print(f"  ç¯©é¸: domains={api['domains']}")
    print(f"  ç¶²ç«™: {api['url']}")

# æ–¹æ¡ˆ 3: ä½¿ç”¨å…¶ä»–é¡ä¼¼æ–°èæºï¼ˆæ›´å®¹æ˜“çˆ¬å–ï¼‰
print("\n\nã€æ–¹æ¡ˆ 3ã€‘æ›¿ä»£æ–°èæºï¼ˆæ›´å®¹æ˜“çˆ¬å–ï¼‰")
print("-" * 70)

easier_sources = [
    {
        "name": "Reuters (è·¯é€ç¤¾)",
        "description": "å…¨çƒè²¡ç¶“æ–°èï¼Œæ–‡ç« å®Œæ•´ï¼Œæœ‰ RSS",
        "rss": "https://www.reutersagency.com/feed/?best-topics=business-finance&post_type=best",
        "website": "https://www.reuters.com/",
    },
    {
        "name": "AP News",
        "description": "ç¾è¯ç¤¾ï¼Œæ¬Šå¨æ–°èä¾†æº",
        "rss": "https://feeds.apnews.com/rss/apnews-business",
        "website": "https://apnews.com/",
    },
    {
        "name": "BBC Business",
        "description": "BBC å•†æ¥­æ–°èï¼Œåœ‹éš›è¦–è§’",
        "rss": "https://feeds.bbci.co.uk/news/business/rss.xml",
        "website": "https://www.bbc.com/news/business",
    },
    {
        "name": "Yahoo Finance",
        "description": "é›…è™è²¡ç¶“ï¼Œæ›´æ–°é »ç¹",
        "rss": "https://finance.yahoo.com/news/rssindex",
        "website": "https://finance.yahoo.com/",
    },
]

# æ¸¬è©¦é€™äº›æ›´å®¹æ˜“çˆ¬å–çš„ä¾†æº
for source in easier_sources:
    print(f"\n{source['name']}:")
    print(f"  èªªæ˜: {source['description']}")
    print(f"  RSS: {source['rss']}")
    print(f"  ç¶²ç«™: {source['website']}")

    try:
        response = requests.get(source["rss"], timeout=10)
        if response.status_code == 200:
            root = ET.fromstring(response.text)
            items = root.findall(".//item")
            print(f"  âœ… RSS å¯ç”¨: {len(items)} å‰‡æ–°è")

            # æ¸¬è©¦çˆ¬å–æ–‡ç« 
            if items:
                test_url = items[0].findtext("link")
                print(f"  æ¸¬è©¦çˆ¬å–: {test_url[:60]}...")
                try:
                    article_resp = requests.get(test_url, timeout=10)
                    if article_resp.status_code == 200:
                        soup = BeautifulSoup(article_resp.text, "html.parser")
                        paragraphs = soup.find_all("p")
                        print(f"  âœ… çˆ¬å–æˆåŠŸ: {len(paragraphs)} å€‹æ®µè½")
                    else:
                        print(f"  âŒ çˆ¬å–å¤±æ•—: {article_resp.status_code}")
                except Exception as e:
                    print(f"  âš ï¸ çˆ¬å–éŒ¯èª¤: {e}")
        else:
            print(f"  âŒ RSS å¤±æ•—: {response.status_code}")
    except Exception as e:
        print(f"  âš ï¸ éŒ¯èª¤: {e}")

# æ–¹æ¡ˆ 4: ä½¿ç”¨ Headless Browser (Selenium/Playwright)
print("\n\nã€æ–¹æ¡ˆ 4ã€‘Headless Browser æ–¹æ¡ˆ")
print("-" * 70)

print("""
Selenium / Playwright:
  å„ªé»:
    - æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨è¡Œç‚ºï¼Œç¹ééƒ¨åˆ†åçˆ¬èŸ²
    - å¯åŸ·è¡Œ JavaScript
    - å¯è™•ç†å‹•æ…‹å…§å®¹
  
  ç¼ºé»:
    - è³‡æºæ¶ˆè€—è¼ƒå¤§
    - é€Ÿåº¦è¼ƒæ…¢
    - å¯èƒ½ä»è¢«è­˜åˆ¥ç‚ºçˆ¬èŸ²
  
  ç‹€æ…‹: Playwright å·²å®‰è£ï¼Œå¯ç›´æ¥ä½¿ç”¨
  
  æ¨è–¦é…ç½®:
    - ä½¿ç”¨ random-useragent
    - è¨­ç½®åˆç†çš„è«‹æ±‚é–“éš” (2-5 ç§’)
    - ä½¿ç”¨ä»£ç†è¼ªæ› (å¦‚æœ‰éœ€è¦)
""")

print("\n" + "=" * 70)
print("æ¨è–¦æ–¹æ¡ˆæ’åº:")
print("=" * 70)
print("""
ã€æ¨è–¦ 1ã€‘ä½¿ç”¨ NewsAPI.org
  - æœ€ç©©å®šï¼Œå®˜æ–¹ API
  - æ”¯æ´ CNN å’Œå…¶ä»–ä¾†æº
  - å…è²»ç‰ˆè¶³å¤ æ—¥å¸¸ä½¿ç”¨

ã€æ¨è–¦ 2ã€‘ä½¿ç”¨ Reuters æˆ– AP News
  - è³ªé‡ç›¸ç•¶æ–¼ CNN
  - RSS å¯ç”¨
  - å®¹æ˜“çˆ¬å–

ã€æ¨è–¦ 3ã€‘ä½¿ç”¨ Yahoo Finance
  - RSS æ›´æ–°å¿«
  - çˆ¬å–æˆåŠŸç‡è¼ƒé«˜
  - å…§å®¹è±å¯Œ

ã€å‚™é¸ã€‘Playwright + CNN
  - æœ€è¤‡é›œä½†å¯èƒ½æˆåŠŸ
  - éœ€è¦èª¿è©¦åçˆ¬èŸ²ç­–ç•¥
  - è³‡æºæ¶ˆè€—å¤§
""")
