import time
import requests
import logging
from typing import Optional
from ..core.config import Config


class AIModelClient:
    def __init__(self, config: Config, logger: logging.Logger):
        self.config = config
        self.logger = logger

        # Provider ç­–ç•¥ï¼ˆå¾ Config è®€å–ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨é»˜èªå€¼ï¼‰
        self.current_provider = getattr(config, "AI_PROVIDER", "auto")
        self.ollama_base_url = getattr(
            config, "OLLAMA_BASE_URL", "http://192.168.2.192:11434"
        )

        # OpenRouter headers
        self.openrouter_headers = {
            "Authorization": f"Bearer {self.config.OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
        }

        # Ollama å„ªå…ˆæ¨¡å‹æ¸…å–®ï¼ˆå·²éæ¿¾ VLï¼‰
        preferred_models = getattr(
            config,
            "OLLAMA_PREFERRED_MODELS",
            [
                "ministral-3:14b-cloud",
                "ministral-3:8b-cloud",
                "ministral-3:3b-cloud",
                "gpt-oss:20b-cloud",
            ],
        )
        exclude_keywords = getattr(
            config, "OLLAMA_EXCLUDE_NAME_KEYWORDS", ["vl", "qwen3-vl"]
        )
        self.ollama_preferred_models = self._filter_ollama_models(
            preferred_models, exclude_keywords
        )

        # æ˜¯å¦å·²ç²å–æœ¬æ©Ÿæ¨¡å‹æ¸…å–®
        self.local_models_fetched = False
        self.available_ollama_models = []

        # è¿½è¹¤å·²ç¶“å¤±æ•—çš„æ¨¡å‹ï¼Œé¿å…é‡è¤‡å˜—è©¦
        self.failed_models = set()

    def _filter_ollama_models(self, preferred: list, exclude_keywords: list) -> list:
        """éæ¿¾ Ollama æ¨¡å‹ï¼šæ’é™¤é—œéµè©å’Œ VL é¡å‹"""
        filtered = []
        for model in preferred:
            # æª¢æŸ¥æ˜¯å¦åœ¨æ’é™¤æ¸…å–®ä¸­
            excluded = any(keyword in model.lower() for keyword in exclude_keywords)
            if excluded:
                self.logger.info(f"è·³éæ’é™¤æ¨¡å‹: {model}")
                continue

            # åªæ¥å—åç¨±å« -cloud çš„æ¨¡å‹ï¼ˆcloud æ¨¡å‹å„ªå…ˆï¼‰
            if "-cloud" in model.lower():
                self.logger.info(f"æ¡ç”¨ cloud æ¨¡å‹: {model}")
                filtered.append(model)

        return filtered

    def _fetch_local_ollama_models(self) -> list:
        """ç²å–æœ¬æ©Ÿ Ollama æ¨¡å‹æ¸…å–®ä¸¦éæ¿¾"""
        try:
            response = requests.get(
                f"{self.ollama_base_url}/api/tags", timeout=self.config.SCRAPE_TIMEOUT
            )
            response.raise_for_status()
            data = response.json()

            models = data.get("models", [])

            # éæ¿¾ VL é¡å‹æ¨¡å‹
            exclude_patterns = ["vl", "qwen3-vl"]
            filtered_models = []

            for model_info in models:
                model_name = model_info.get("name", "")

                # æ’é™¤ VL é¡å‹
                if any(pattern in model_name.lower() for pattern in exclude_patterns):
                    self.logger.info(f"æ’é™¤ VL æ¨¡å‹: {model_name}")
                    continue

                # å¦‚æœå•Ÿç”¨ cloud å„ªå…ˆï¼Œåªä¿ç•™ cloud æ¨¡å‹æˆ–æœ¬æ©Ÿæ¨¡å‹ï¼ˆä¸å« :cloudï¼‰
                if getattr(self.config, "OLLAMA_PREFER_CLOUD_MODELS", True):
                    if ":cloud" not in model_name and "cloud" not in model_name:
                        self.logger.info(
                            f"è·³éé cloud æ¨¡å‹ï¼ˆcloud æ¨¡å¼ï¼‰: {model_name}"
                        )
                        continue

                filtered_models.append(model_name)

            self.available_ollama_models = filtered_models
            self.local_models_fetched = True

            self.logger.info(f"âœ… ç²å–æœ¬æ©Ÿ Ollama æ¨¡å‹æ¸…å–®: {len(filtered_models)} å€‹")
            if filtered_models:
                self.logger.info(f"å¯ç”¨æ¨¡å‹: {', '.join(filtered_models[:5])}...")
            return filtered_models

        except Exception as e:
            self.logger.warning(f"ç²å– Ollama æ¨¡å‹æ¸…å–®å¤±æ•—: {e}")
            return []

    def _call_openrouter(self, prompt: str, model_name: str) -> Optional[str]:
        """å‘¼å« OpenRouter API"""
        self.logger.info(f"ğŸ§  æ­£åœ¨ä½¿ç”¨æ¨¡å‹: {model_name} (OpenRouter)")
        payload = {
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": self.config.OPENROUTER_MAX_TOKENS,
        }

        max_retries = self.config.OPENROUTER_MAX_RETRIES

        for attempt in range(max_retries):
            try:
                res = requests.post(
                    self.config.OPENROUTER_API_URL,
                    headers=self.openrouter_headers,
                    json=payload,
                    timeout=self.config.OPENROUTER_TIMEOUT,
                )
                res.raise_for_status()
                response_data = res.json()
                content = (
                    response_data.get("choices", [{}])[0]
                    .get("message", {})
                    .get("content")
                )
                if content:
                    self.logger.info(f"âœ… æ¨¡å‹ {model_name} æˆåŠŸè¿”å›å…§å®¹ã€‚")
                    return content.strip()
                else:
                    raise ValueError(
                        f"AI æ¨¡å‹è¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„ contentã€‚Response: {response_data}"
                    )
            except (
                requests.exceptions.RequestException,
                KeyError,
                IndexError,
                TypeError,
                ValueError,
            ) as e:
                error_msg = str(e)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ç™¼ç”ŸéŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{max_retries}): {e}"
                )

                # 401 Unauthorized è¡¨ç¤ºæˆæ¬Šå•é¡Œï¼Œé‡è©¦ç„¡æ„ç¾©
                if "401" in error_msg or "Unauthorized" in error_msg:
                    self.logger.error(f"âŒ OpenRouter æˆæ¬Šå¤±æ•—ï¼ˆ401ï¼‰: {model_name}")
                    return None

                if attempt < max_retries - 1:
                    time.sleep(self.config.OPENROUTER_BASE_DELAY * (2**attempt))
                else:
                    self.logger.error(
                        f"âŒ æ¨¡å‹ {model_name} åœ¨ {max_retries} æ¬¡é‡è©¦å¾Œä¾ç„¶å¤±æ•—ã€‚"
                    )
                    return None

    def _call_ollama_chat(self, prompt: str, model_name: str) -> Optional[str]:
        """å‘¼å« Ollama API"""
        self.logger.info(f"ğŸ§  æ­£åœ¨ä½¿ç”¨æ¨¡å‹: {model_name} (Ollama)")

        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": "è«‹ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡å›ç­”ï¼Œé¿å…ç°¡é«”å­—ã€‚"},
                {"role": "user", "content": prompt},
            ],
            "stream": False,
        }

        try:
            response = requests.post(
                f"{self.ollama_base_url}/api/chat",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=self.config.SCRAPE_TIMEOUT,
            )
            response.raise_for_status()
            response_data = response.json()

            # åªå– message.contentï¼Œå¿½ç•¥ thinking æ¬„ä½
            message = response_data.get("message", {})
            content = message.get("content", "")

            if content:
                self.logger.info(f"âœ… æ¨¡å‹ {model_name} æˆåŠŸè¿”å›å…§å®¹ã€‚")
                return content.strip()
            else:
                raise ValueError("Ollama è¿”å›äº†ç©ºçš„ content")

        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹ {model_name} å‘¼å«å¤±æ•—: {e}")
            # æ¨™è¨˜æ¨¡å‹å¤±æ•—
            self.failed_models.add(model_name)
            self.logger.warning(f"æ¨¡å‹ {model_name} å·²åŠ å…¥å¤±æ•—æ¸…å–®")
            # æ¨¡å‹å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–æ¨¡å‹
            self.logger.info("å˜—è©¦ä½¿ç”¨å…¶ä»– Ollama æ¨¡å‹")
            return self._try_ollama_models_implicitly(prompt)

    def _try_ollama_models_implicitly(
        self, prompt: str, exclude: bool = False
    ) -> Optional[str]:
        """éš±æ€§å˜—è©¦ Ollama æ¨¡å‹ï¼ˆç•¶æŒ‡å®šæ¨¡å‹å¤±æ•ˆæ™‚ï¼‰"""
        if exclude:
            self.logger.info("è·³ééš±æ€§å˜—è©¦ï¼ˆå·²æ’é™¤è©²æ¨¡å‹ï¼‰")
            return None

        # ç²å–æœ¬åœ°æ¨¡å‹æ¸…å–®ï¼ˆä¸éæ¿¾ï¼Œä¿ç•™æ‰€æœ‰æ¨¡å‹ï¼‰
        try:
            response = requests.get(
                f"{self.ollama_base_url}/api/tags", timeout=self.config.SCRAPE_TIMEOUT
            )
            response.raise_for_status()
            data = response.json()
            all_models = [m.get("name", "") for m in data.get("models", [])]
            self.logger.info(f"ç²å– {len(all_models)} å€‹æœ¬åœ°æ¨¡å‹")

            # æ’é™¤ VLé¡å‹æ¨¡å‹å’Œå·²ç¶“å¤±æ•—çš„æ¨¡å‹
            exclude_keywords = getattr(
                self.config, "OLLAMA_EXCLUDE_NAME_KEYWORDS", ["vl", "qwen3-vl"]
            )
            filtered_models = []
            for model in all_models:
                if any(keyword in model.lower() for keyword in exclude_keywords):
                    continue
                if model in self.failed_models:
                    continue
                filtered_models.append(model)

            all_models = filtered_models
            self.logger.info(
                f"éæ¿¾å¾Œå‰©é¤˜ {len(all_models)} å€‹æ¨¡å‹ï¼ˆå·²æ’é™¤ {len(self.failed_models)} å€‹å¤±æ•—æ¨¡å‹ï¼‰"
            )
        except Exception as e:
            self.logger.warning(f"ç²å–æœ¬åœ°æ¨¡å‹æ¸…å–®å¤±æ•—: {e}")
            return None

        # å˜—è©¦å„ªå…ˆæ¨¡å‹ï¼ˆå¦‚æœå•Ÿç”¨äº† cloud å„ªå…ˆï¼‰
        if getattr(self.config, "OLLAMA_PREFER_CLOUD_MODELS", True):
            for model in self.ollama_preferred_models:
                if model in self.failed_models:
                    self.logger.warning(f"è·³éå·²å¤±æ•—çš„å„ªå…ˆæ¨¡å‹: {model}")
                    continue

                if model in all_models:
                    self.logger.info(f"å˜—è©¦å„ªå…ˆ cloud æ¨¡å‹: {model}")
                    result = self._call_ollama_chat(prompt, model)
                    if result:
                        self.logger.info(f"âœ… æ¨¡å‹ {model} æˆåŠŸ")
                        return result
                    else:
                        # è¨˜éŒ„å¤±æ•—çš„æ¨¡å‹
                        self.failed_models.add(model)
                        self.logger.warning(f"å„ªå…ˆæ¨¡å‹ {model} å¤±æ•—ï¼Œå·²åŠ å…¥å¤±æ•—æ¸…å–®")
                else:
                    self.logger.warning(f"å„ªå…ˆæ¨¡å‹ {model} ä¸åœ¨æœ¬åœ°æ¸…å–®")

        # å¦‚æœå•Ÿç”¨ try_all_models æˆ–å„ªå…ˆæ¨¡å‹éƒ½å¤±æ•—ï¼Œå˜—è©¦æ‰€æœ‰æœ¬åœ°æ¨¡å‹
        if getattr(self.config, "OLLAMA_TRY_ALL_MODELS", True):
            self.logger.info("å˜—è©¦æ‰€æœ‰æœ¬åœ°æ¨¡å‹")
            for model in all_models:
                # è·³éå·²ç¶“å˜—è©¦éçš„å„ªå…ˆæ¨¡å‹
                if model in self.ollama_preferred_models:
                    continue

                if model in self.failed_models:
                    continue

                self.logger.info(f"å˜—è©¦æœ¬åœ°æ¨¡å‹: {model}")
                result = self._call_ollama_chat(prompt, model)
                if result:
                    self.logger.info(f"âœ… æ¨¡å‹ {model} æˆåŠŸ")
                    return result
                else:
                    # è¨˜éŒ„å¤±æ•—çš„æ¨¡å‹
                    self.failed_models.add(model)
                    self.logger.warning(f"æœ¬åœ°æ¨¡å‹ {model} å¤±æ•—ï¼Œå·²åŠ å…¥å¤±æ•—æ¸…å–®")

        self.logger.warning("æ‰€æœ‰ Ollama æ¨¡å‹éƒ½å¤±æ•—")
        return None

        # ç²å–æœ¬åœ°æ¨¡å‹æ¸…å–®ï¼ˆä¸éæ¿¾ï¼Œä¿ç•™æ‰€æœ‰æ¨¡å‹ï¼‰
        try:
            response = requests.get(
                f"{self.ollama_base_url}/api/tags", timeout=self.config.SCRAPE_TIMEOUT
            )
            response.raise_for_status()
            data = response.json()
            all_models = [m.get("name", "") for m in data.get("models", [])]
            self.logger.info(f"ç²å– {len(all_models)} å€‹æœ¬åœ°æ¨¡å‹")

            # æ’é™¤ VL é¡å‹æ¨¡å‹
            exclude_keywords = getattr(
                self.config, "OLLAMA_EXCLUDE_NAME_KEYWORDS", ["vl", "qwen3-vl"]
            )
            filtered_models = []
            for model in all_models:
                if any(keyword in model.lower() for keyword in exclude_keywords):
                    continue
                filtered_models.append(model)

            all_models = filtered_models
            self.logger.info(f"éæ¿¾å¾Œå‰©é¤˜ {len(all_models)} å€‹æ¨¡å‹")
        except Exception as e:
            self.logger.warning(f"ç²å–æœ¬åœ°æ¨¡å‹æ¸…å–®å¤±æ•—: {e}")
            return None

        # å˜—è©¦å„ªå…ˆæ¨¡å‹ï¼ˆå¦‚æœå•Ÿç”¨äº† cloud å„ªå…ˆï¼‰
        if getattr(self.config, "OLLAMA_PREFER_CLOUD_MODELS", True):
            for model in self.ollama_preferred_models:
                if model in all_models:
                    self.logger.info(f"å˜—è©¦å„ªå…ˆ cloud æ¨¡å‹: {model}")
                    result = self._call_ollama_chat(prompt, model)
                    if result:
                        self.logger.info(f"âœ… æ¨¡å‹ {model} æˆåŠŸ")
                        return result
                else:
                    self.logger.warning(f"å„ªå…ˆæ¨¡å‹ {model} ä¸åœ¨æœ¬åœ°æ¸…å–®")

        # å¦‚æœå•Ÿç”¨ try_all_models æˆ–å„ªå…ˆæ¨¡å‹éƒ½å¤±æ•—ï¼Œå˜—è©¦æ‰€æœ‰æœ¬åœ°æ¨¡å‹
        if getattr(self.config, "OLLAMA_TRY_ALL_MODELS", True):
            self.logger.info("å˜—è©¦æ‰€æœ‰æœ¬åœ°æ¨¡å‹")
            for model in all_models:
                # è·³éå·²ç¶“å˜—è©¦éçš„å„ªå…ˆæ¨¡å‹
                if model in self.ollama_preferred_models:
                    continue

                self.logger.info(f"å˜—è©¦æœ¬åœ°æ¨¡å‹: {model}")
                result = self._call_ollama_chat(prompt, model)
                if result:
                    self.logger.info(f"âœ… æ¨¡å‹ {model} æˆåŠŸ")
                    return result

        self.logger.warning("æ‰€æœ‰ Ollama æ¨¡å‹éƒ½å¤±æ•—")
        return None

    def _handle_all_models_failed(self) -> Optional[str]:
        """è™•ç†æ‰€æœ‰æ¨¡å‹éƒ½å¤±æ•—çš„æƒ…æ³"""
        on_all_fail = getattr(self.config, "OLLAMA_ON_ALL_FAIL", "terminate")
        if on_all_fail == "fallback_openrouter":
            self.logger.info("Ollama å…¨éƒ¨å¤±æ•—ï¼Œfallback åˆ° OpenRouter")
            # ä½† OpenRouter ä¹Ÿå¯èƒ½æ²’ keyï¼Œé€™è£¡åªåšæ¨™è¨˜
            return None
        elif on_all_fail == "terminate":
            self.logger.critical("âŒ æ‰€æœ‰ Ollama æ¨¡å‹å‡å·²å˜—è©¦å¤±æ•—ï¼Œçµ‚æ­¢æµç¨‹ã€‚")
            raise RuntimeError("All Ollama models failed, terminating workflow.")
        else:
            self.logger.critical("âŒ æ‰€æœ‰ AI æ¨¡å‹å‡å·²å˜—è©¦å¤±æ•—ã€‚")
            return None

    def call(
        self, prompt: str, model_name: str = None, max_model_failures: int = 3
    ) -> Optional[str]:
        """çµ±ä¸€å‘¼å«å…¥å£ï¼šæ ¹æ“š provider é¸æ“‡ OpenRouter æˆ– Ollama"""

        # å¦‚æœæ²’æŒ‡å®š model_nameï¼Œä½¿ç”¨é»˜èª
        if not model_name:
            if self.current_provider == "openrouter":
                model_name = (
                    self.config.AVAILABLE_MODELS[0]
                    if self.config.AVAILABLE_MODELS
                    else "mistralai/devstral-2512:free"
                )
            elif self.current_provider == "ollama":
                model_name = (
                    self.ollama_preferred_models[0]
                    if self.ollama_preferred_models
                    else "qwen3:14b"
                )
            else:  # auto
                model_name = (
                    self.config.AVAILABLE_MODELS[0]
                    if self.config.AVAILABLE_MODELS
                    else "mistralai/devstral-2512:free"
                )

        # æ ¹æ“š provider é¸æ“‡å‘¼å«æ–¹å¼
        if self.current_provider == "openrouter":
            return self._call_openrouter(prompt, model_name)
        elif self.current_provider == "ollama":
            return self._call_ollama_chat(prompt, model_name)
        else:  # auto: å„ªå…ˆ OpenRouter
            self.logger.info("Provider: auto (å„ªå…ˆ OpenRouter)")
            result = self._call_openrouter(prompt, model_name)
            if result:
                return result
            else:
                self.logger.warning("OpenRouter å¤±æ•—ï¼Œfallback åˆ° Ollama")
                self.current_provider = "ollama"
                # å˜—è©¦éš±æ€§èª¿ç”¨ï¼ˆæ¨¡å‹å¤±æ•ˆæ™‚è‡ªå‹•æ›ä¸‹ä¸€å€‹ï¼‰
                return self._try_ollama_models_implicitly(prompt)

        self.logger.critical("âŒ æ‰€æœ‰å¯ç”¨ AI æ¨¡å‹å‡å·²å˜—è©¦å¤±æ•—ã€‚")
        return None
